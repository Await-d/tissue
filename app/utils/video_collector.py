"""
è§†é¢‘æ”¶é›†å™¨ - èšåˆå„ä¸ªçˆ¬è™«ç½‘ç«™çš„è§†é¢‘æ•°æ®
"""
import time
import traceback
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from random import randint

from app.utils import spider
from app.utils.async_logger import get_logger

# è·å–é€‚åˆæ™ºèƒ½ä¸‹è½½çš„æ—¥å¿—è®°å½•å™¨
logger = get_logger()


class VideoCollector:
    """è§†é¢‘æ”¶é›†å™¨"""
    
    def __init__(self):
        self.spiders = [
            spider.JavdbSpider(),
            # å¯ä»¥æ·»åŠ å…¶ä»–çˆ¬è™«
        ]
        # æ·»åŠ ç¼“å­˜å­˜å‚¨
        self._cache = {}
        # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰- ä¸´æ—¶è®¾ç½®ä¸º0ä»¥å¼ºåˆ¶åˆ·æ–°
        self.cache_ttl_hours = 0
    
    def get_trending_videos(self, time_range: str = "week", max_pages: int = 3) -> List[Dict[str, Any]]:
        """è·å–çƒ­é—¨è§†é¢‘"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"trending_{time_range}_{max_pages}"
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ä»ç¼“å­˜è·å–çƒ­é—¨è§†é¢‘æ•°æ®ï¼Œå…± {len(cached_data)} ä¸ª")
            return cached_data
        
        all_videos = []
        
        for spider_instance in self.spiders:
            try:
                logger.info(f"ä» {spider_instance.name} è·å–çƒ­é—¨è§†é¢‘")
                
                for page in range(1, max_pages + 1):
                    videos = spider_instance.get_trending_videos(page, time_range)
                    
                    if not videos:
                        break
                    
                    all_videos.extend(videos)
            except Exception as e:
                logger.error(f"è·å–çƒ­é—¨è§†é¢‘å‡ºé”™: {str(e)}")
                logger.debug(traceback.format_exc())
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, all_videos)
        return all_videos
    
    def get_latest_videos(self, max_pages: int = 3, days: int = 7) -> List[Dict[str, Any]]:
        """è·å–æœ€æ–°è§†é¢‘"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"latest_{max_pages}_{days}"
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ä»ç¼“å­˜è·å–æœ€æ–°è§†é¢‘æ•°æ®ï¼Œå…± {len(cached_data)} ä¸ª")
            return cached_data
            
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        all_videos = []
        unique_nums = set()
        
        for spider_instance in self.spiders:
            try:
                for page in range(1, max_pages + 1):
                    videos = spider_instance.get_latest_videos(page)
                    
                    if not videos:
                        break
                    
                    # æ£€æŸ¥å‘å¸ƒæ—¥æœŸ
                    for video in videos:
                        try:
                            # å¦‚æœæ²¡æœ‰æ—¥æœŸæˆ–è€…æ—¥æœŸæ ¼å¼ä¸å¯¹ï¼Œé»˜è®¤æ·»åŠ 
                            if 'release_date' not in video or not video['release_date']:
                                all_videos.append(video)
                                unique_nums.add(video['num'])
                                continue
                            
                            # è§£ææ—¥æœŸ
                            release_date = datetime.strptime(video['release_date'], '%Y-%m-%d')
                            
                            # æ£€æŸ¥æ—¥æœŸèŒƒå›´
                            if start_date <= release_date <= end_date:
                                # é¿å…é‡å¤
                                if video['num'] not in unique_nums:
                                    all_videos.append(video)
                                    unique_nums.add(video['num'])
                        except Exception as e:
                            logger.error(f"è§£æè§†é¢‘æ—¥æœŸå‡ºé”™: {str(e)}, è§†é¢‘: {video.get('num')}")
                            # å‡ºé”™æ—¶é»˜è®¤æ·»åŠ 
                            if video['num'] not in unique_nums:
                                all_videos.append(video)
                                unique_nums.add(video['num'])
            except Exception as e:
                logger.error(f"è·å–æœ€æ–°è§†é¢‘å‡ºé”™: {str(e)}")
                logger.debug(traceback.format_exc())
        
        logger.info(f"æ”¶é›†åˆ° {len(all_videos)} ä¸ªç‹¬ç‰¹çš„æœ€æ–°è§†é¢‘")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, all_videos)
        return all_videos

    def get_ranking_videos(self, video_type: str = 'censored', cycle: str = 'daily', max_pages: int = 3) -> List[Dict[str, Any]]:
        """è·å–æ’è¡Œæ¦œè§†é¢‘ï¼ŒåŒ…å«è¯„åˆ†å’Œè¯„è®ºä¿¡æ¯ï¼Œä¼˜åŒ–æ™ºèƒ½ä¸‹è½½è§„åˆ™æ€§èƒ½"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"ranking_{video_type}_{cycle}_{max_pages}"
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ä»ç¼“å­˜è·å–æ’è¡Œæ¦œè§†é¢‘æ•°æ®ï¼Œå…± {len(cached_data)} ä¸ª")
            return cached_data
        
        all_videos = []
        unique_nums = set()
        
        for spider_instance in self.spiders:
            try:
                # ä½¿ç”¨æ–°çš„è·å–æ’è¡Œæ¦œæ–¹æ³•ï¼Œç›´æ¥åŒ…å«è¯„åˆ†å’Œè¯„è®ºä¿¡æ¯
                if hasattr(spider_instance, 'get_ranking_with_details'):
                    videos = spider_instance.get_ranking_with_details(video_type, cycle, max_pages)
                    
                    for video in videos:
                        # é¿å…é‡å¤
                        if video['num'] not in unique_nums:
                            all_videos.append(video)
                            unique_nums.add(video['num'])
                else:
                    # é™çº§åˆ°åŸæœ‰æ–¹æ³•
                    logger.warning(f"çˆ¬è™« {spider_instance.name} ä¸æ”¯æŒget_ranking_with_detailsæ–¹æ³•ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                    videos = spider_instance.get_latest_videos(max_pages)
                    for video in videos:
                        if video['num'] not in unique_nums:
                            all_videos.append(video)
                            unique_nums.add(video['num'])
                    
            except Exception as e:
                logger.error(f"è·å–æ’è¡Œæ¦œè§†é¢‘å‡ºé”™: {str(e)}")
                logger.debug(traceback.format_exc())
        
        logger.info(f"æ”¶é›†åˆ° {len(all_videos)} ä¸ªç‹¬ç‰¹çš„æ’è¡Œæ¦œè§†é¢‘ï¼ŒåŒ…å«è¯„åˆ†å’Œè¯„è®ºä¿¡æ¯")
        
        # è¾“å‡ºå‰5ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
        for i, video in enumerate(all_videos[:5]):
            logger.info(f"æ’è¡Œæ¦œè§†é¢‘ {i+1}: {video.get('num')} - è¯„åˆ†: {video.get('rating')} - è¯„è®º: {video.get('comments')} - è¯„è®ºæ•°: {video.get('comments_count')}")
        
        # ç»Ÿè®¡æœ‰æ•ˆè¯„åˆ†å’Œè¯„è®ºæ•°æ®
        valid_ratings = [v for v in all_videos if v.get('rating') is not None]
        valid_comments = [v for v in all_videos if v.get('comments') is not None and v.get('comments') > 0]
        valid_comments_count = [v for v in all_videos if v.get('comments_count') is not None and v.get('comments_count') > 0]
        logger.info(f"æœ‰æ•ˆè¯„åˆ†æ•°æ®: {len(valid_ratings)}/{len(all_videos)}, æœ‰æ•ˆè¯„è®ºæ•°æ®: {len(valid_comments)}/{len(all_videos)}, æœ‰æ•ˆè¯„è®ºæ•°æ•°æ®: {len(valid_comments_count)}/{len(all_videos)}")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, all_videos)
        return all_videos
    
    def get_videos_by_criteria(self, 
                          min_rating: Optional[float] = None, 
                          min_comments: Optional[int] = None,
                          is_uncensored: Optional[bool] = None,
                          is_hd: Optional[bool] = None,
                          is_zh: Optional[bool] = None,
                          required_actor_id: Optional[str] = None,
                          exclude_actor_id: Optional[str] = None,
                          required_tags: Optional[List[str]] = None,
                          exclude_tags: Optional[List[str]] = None,
                          max_pages: int = 3,
                          days: int = 7) -> List[Dict[str, Any]]:
        """æ ¹æ®æ¡ä»¶ç­›é€‰è§†é¢‘ï¼Œä¼˜åŒ–æ€§èƒ½ï¼šä¼˜å…ˆä½¿ç”¨æ’è¡Œæ¦œæ•°æ®é¿å…å•ç‹¬è®¿é—®è¯¦æƒ…é¡µ"""
        # æ„å»ºç¼“å­˜é”®
        cache_params = f"{min_rating}_{min_comments}_{is_uncensored}_{is_hd}_{is_zh}_{required_actor_id}_{exclude_actor_id}_{required_tags}_{exclude_tags}_{max_pages}_{days}"
        cache_key = f"criteria_{hash(cache_params)}"
        
        # æ£€æŸ¥ç¼“å­˜
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ä»ç¼“å­˜è·å–ç­›é€‰è§†é¢‘æ•°æ®ï¼Œå…± {len(cached_data)} ä¸ª")
            return cached_data
        
        # ä¼˜åŒ–ç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨æ’è¡Œæ¦œæ•°æ®ï¼ˆå·²åŒ…å«è¯„åˆ†ã€è¯„è®ºã€è´¨é‡æ ‡ç­¾ï¼‰
        filtered_videos = []
        
        # 1. å…ˆä»æ’è¡Œæ¦œè·å–æœ‰è¯„åˆ†å’Œè¯„è®ºçš„è§†é¢‘ï¼ˆæœ‰ç å’Œæ— ç ï¼‰
        logger.info("å¼€å§‹ä»æ’è¡Œæ¦œè·å–è§†é¢‘æ•°æ®ï¼Œé¿å…è®¿é—®è¯¦æƒ…é¡µ...")
        
        # è·å–æœ‰ç æ’è¡Œæ¦œ
        censored_videos = self.get_ranking_videos('censored', 'daily', max_pages)
        filtered_videos.extend(censored_videos)
        
        # è·å–æ— ç æ’è¡Œæ¦œ
        uncensored_videos = self.get_ranking_videos('uncensored', 'daily', max_pages)
        filtered_videos.extend(uncensored_videos)
        
        logger.info(f"ä»æ’è¡Œæ¦œè·å–åˆ° {len(filtered_videos)} ä¸ªè§†é¢‘ï¼ˆåŒ…å«æœ‰ç å’Œæ— ç ï¼‰ï¼Œå¼€å§‹åŸºç¡€ç­›é€‰...")
        
        # 2. å¯¹æ’è¡Œæ¦œè§†é¢‘è¿›è¡ŒåŸºç¡€ç­›é€‰ï¼ˆè¿™äº›è§†é¢‘å·²ç»åŒ…å«è¯„åˆ†å’Œè¯„è®ºä¿¡æ¯ï¼‰
        basic_filtered = []
        logger.info(f"å¼€å§‹è¯¦ç»†ç­›é€‰ï¼Œç­›é€‰æ¡ä»¶: æœ€ä½è¯„åˆ†={min_rating}, æœ€ä½è¯„è®ºæ•°={min_comments}, æ— ç ={is_uncensored}, é«˜æ¸…={is_hd}, ä¸­æ–‡={is_zh}")
        
        for i, video in enumerate(filtered_videos, 1):
            video_num = video.get('num', 'Unknown')
            video_title = video.get('title', 'Unknown')[:30]  # æˆªå–å‰30ä¸ªå­—ç¬¦
            
            # è·å–è§†é¢‘çš„è¯„åˆ†å’Œè¯„è®ºæ•°æ®
            video_rating = video.get('rating')
            video_comments = video.get('comments', 0)
            video_comments_count = video.get('comments_count', 0)
            
            logger.info(f"[{i}/{len(filtered_videos)}] æ£€æŸ¥è§†é¢‘: {video_num} - {video_title}")
            logger.info(f"  è¯„åˆ†: {video_rating} (ç±»å‹: {type(video_rating).__name__})")
            logger.info(f"  è¯„è®º: {video_comments} (ç±»å‹: {type(video_comments).__name__})")
            logger.info(f"  è¯„è®ºæ•°: {video_comments_count} (ç±»å‹: {type(video_comments_count).__name__})")
            
            # å°è¯•ä»å¤šä¸ªå­—æ®µè·å–è¯„è®ºæ•°
            if video_comments == 0 and video_comments_count != 0:
                video_comments = video_comments_count
                logger.info(f"è§†é¢‘ {video.get('num')} ä½¿ç”¨ comments_count å­—æ®µ: {video_comments}")
            
            # è¯„åˆ†ç­›é€‰
            rating_pass = True
            if min_rating is not None and min_rating > 0:
                if video_rating is not None:
                    try:
                        rating_float = float(video_rating)
                        min_rating_float = float(min_rating)
                        rating_pass = rating_float >= min_rating_float
                        logger.info(f"  ğŸ“Š è¯„åˆ†æ£€æŸ¥: {rating_float} >= {min_rating_float} -> {'âœ… é€šè¿‡' if rating_pass else 'âŒ ä¸é€šè¿‡'}")
                        if not rating_pass:
                            logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è¯„åˆ† {rating_float} ä½äºè¦æ±‚ {min_rating_float}")
                            continue
                    except (ValueError, TypeError) as e:
                        logger.warning(f"  âš ï¸  è¯„åˆ†è½¬æ¢å¤±è´¥: {video_rating} ({type(video_rating).__name__}), é”™è¯¯: {e}")
                        logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è¯„åˆ†æ•°æ®æ— æ•ˆ")
                        continue
                else:
                    logger.info(f"  ğŸ“Š è¯„åˆ†æ£€æŸ¥: æ— è¯„åˆ†æ•°æ® -> âŒ ä¸é€šè¿‡")
                    logger.info(f"  â­ï¸  è·³è¿‡åŸå› : æ— è¯„åˆ†æ•°æ®")
                    continue
            else:
                logger.info(f"  ğŸ“Š è¯„åˆ†æ£€æŸ¥: æ— è¦æ±‚ -> âœ… è·³è¿‡æ£€æŸ¥")
                
            # è¯„è®ºæ•°ç­›é€‰
            comments_pass = True
            if min_comments is not None and min_comments > 0:
                # å°è¯•ä»å¤šä¸ªå­—æ®µè·å–è¯„è®ºæ•°
                final_comments = video_comments
                if video_comments == 0 and video_comments_count != 0:
                    final_comments = video_comments_count
                    logger.info(f"  ğŸ“ ä½¿ç”¨ comments_count å­—æ®µ: {final_comments}")
                
                if final_comments is not None and final_comments > 0:
                    try:
                        comments_int = int(final_comments)
                        min_comments_int = int(min_comments)
                        comments_pass = comments_int >= min_comments_int
                        logger.info(f"  ğŸ’¬ è¯„è®ºæ•°æ£€æŸ¥: {comments_int} >= {min_comments_int} -> {'âœ… é€šè¿‡' if comments_pass else 'âŒ ä¸é€šè¿‡'}")
                        if not comments_pass:
                            logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è¯„è®ºæ•° {comments_int} ä½äºè¦æ±‚ {min_comments_int}")
                            continue
                    except (ValueError, TypeError) as e:
                        logger.warning(f"  âš ï¸  è¯„è®ºæ•°è½¬æ¢å¤±è´¥: {final_comments} ({type(final_comments).__name__}), é”™è¯¯: {e}")
                        logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è¯„è®ºæ•°æ•°æ®æ— æ•ˆ")
                        continue
                else:
                    logger.info(f"  ğŸ’¬ è¯„è®ºæ•°æ£€æŸ¥: è¯„è®ºæ•°ä¸º0 -> âŒ ä¸é€šè¿‡")
                    logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è¯„è®ºæ•°ä¸º0ï¼Œä½äºè¦æ±‚ {min_comments}")
                    continue
            else:
                logger.info(f"  ğŸ’¬ è¯„è®ºæ•°æ£€æŸ¥: æ— è¦æ±‚ -> âœ… è·³è¿‡æ£€æŸ¥")
            
            # è´¨é‡è¦æ±‚ç­›é€‰ï¼ˆæ’è¡Œæ¦œæ•°æ®å·²åŒ…å«è¿™äº›ä¿¡æ¯ï¼‰
            quality_checks = []
            quality_pass = True
            
            if is_uncensored is not None:
                video_uncensored = video.get('is_uncensored', False)
                uncensored_pass = video_uncensored == is_uncensored
                quality_checks.append(f"æ— ç ={video_uncensored}{'âœ…' if uncensored_pass else 'âŒ'}")
                if not uncensored_pass:
                    quality_pass = False
                    
            if is_hd is not None:
                video_hd = video.get('is_hd', False)
                hd_pass = video_hd == is_hd
                quality_checks.append(f"é«˜æ¸…={video_hd}{'âœ…' if hd_pass else 'âŒ'}")
                if not hd_pass:
                    quality_pass = False
                    
            if is_zh is not None:
                video_zh = video.get('is_zh', False)
                zh_pass = video_zh == is_zh
                quality_checks.append(f"ä¸­æ–‡={video_zh}{'âœ…' if zh_pass else 'âŒ'}")
                if not zh_pass:
                    quality_pass = False
            
            if quality_checks:
                logger.info(f"  ğŸ¬ è´¨é‡æ£€æŸ¥: {', '.join(quality_checks)} -> {'âœ… é€šè¿‡' if quality_pass else 'âŒ ä¸é€šè¿‡'}")
                if not quality_pass:
                    logger.info(f"  â­ï¸  è·³è¿‡åŸå› : è´¨é‡è¦æ±‚ä¸ç¬¦åˆ")
                    continue
            else:
                logger.info(f"  ğŸ¬ è´¨é‡æ£€æŸ¥: æ— è¦æ±‚ -> âœ… è·³è¿‡æ£€æŸ¥")
            
            logger.info(f"  âœ… {video_num} é€šè¿‡æ‰€æœ‰ç­›é€‰æ¡ä»¶ï¼Œå·²æ·»åŠ åˆ°ç»“æœåˆ—è¡¨")
            basic_filtered.append(video)
        
        logger.info(f"åŸºç¡€ç­›é€‰åå‰©ä½™ {len(basic_filtered)} ä¸ªè§†é¢‘")
        
        # 3. å¯¹äºéœ€è¦æ¼”å‘˜æˆ–æ ‡ç­¾ä¿¡æ¯çš„ç­›é€‰ï¼Œæ‰è®¿é—®è¯¦æƒ…é¡µï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
        final_filtered = []
        need_detail_check = bool(required_actor_id or exclude_actor_id or required_tags or exclude_tags)
        
        for video in basic_filtered:
            if need_detail_check:
                # åªæœ‰åœ¨éœ€è¦æ¼”å‘˜æˆ–æ ‡ç­¾ä¿¡æ¯æ—¶æ‰è·å–è¯¦æƒ…
                video_detail = self._get_video_detail(video['num'])
                
                if not video_detail:
                    # å¦‚æœè·å–è¯¦æƒ…å¤±è´¥ï¼Œä½†å·²ç»é€šè¿‡åŸºç¡€ç­›é€‰ï¼Œä»ç„¶ä¿ç•™
                    video['detail_missing'] = True
                    final_filtered.append(video)
                    continue
                
                # åˆå¹¶è¯¦æƒ…ä¿¡æ¯
                video.update(video_detail)
                
                # æ£€æŸ¥æ¼”å‘˜
                if required_actor_id:
                    actors = video.get('actors', [])
                    actor_ids = [a.get('id') for a in actors]
                    if required_actor_id not in actor_ids:
                        continue
                
                if exclude_actor_id:
                    actors = video.get('actors', [])
                    actor_ids = [a.get('id') for a in actors]
                    if exclude_actor_id in actor_ids:
                        continue
                
                # æ£€æŸ¥æ ‡ç­¾
                if required_tags:
                    tags = video.get('tags', [])
                    tag_names = [t.get('name').lower() for t in tags]
                    if not all(tag.lower() in tag_names for tag in required_tags):
                        continue
                
                if exclude_tags:
                    tags = video.get('tags', [])
                    tag_names = [t.get('name').lower() for t in tags]
                    if any(tag.lower() in tag_names for tag in exclude_tags):
                        continue
            
            # é€šè¿‡æ‰€æœ‰ç­›é€‰æ¡ä»¶
            final_filtered.append(video)
        
        # 4. å¦‚æœæ’è¡Œæ¦œæ•°æ®ä¸è¶³ï¼Œè¡¥å……æœ€æ–°è§†é¢‘æ•°æ®
        if len(final_filtered) < 20:  # å¦‚æœç»“æœå¤ªå°‘ï¼Œè¡¥å……ä¸€äº›æœ€æ–°è§†é¢‘
            logger.info(f"æ’è¡Œæ¦œç­›é€‰ç»“æœè¾ƒå°‘({len(final_filtered)}ä¸ª)ï¼Œè¡¥å……æœ€æ–°è§†é¢‘æ•°æ®...")
            
            latest_videos = self.get_latest_videos(max_pages, days)
            existing_nums = {v['num'] for v in final_filtered}
            
            for video in latest_videos:
                if video['num'] in existing_nums:
                    continue  # é¿å…é‡å¤
                
                # å¯¹è¡¥å……çš„è§†é¢‘è¿›è¡ŒåŒæ ·çš„ç­›é€‰é€»è¾‘
                video_rating = video.get('rating')
                if min_rating is not None and min_rating > 0 and video_rating is not None and float(video_rating) < float(min_rating):
                    continue
                video_comments = video.get('comments', 0)
                if min_comments is not None and min_comments > 0 and video_comments is not None and int(video_comments) < int(min_comments):
                    continue
                
                # éœ€è¦è¯¦æƒ…ä¿¡æ¯çš„ç­›é€‰
                if need_detail_check or is_uncensored is not None or is_hd is not None or is_zh is not None:
                    video_detail = self._get_video_detail(video['num'])
                    if video_detail:
                        video.update(video_detail)
                        
                        if is_uncensored is not None and video.get('is_uncensored', False) != is_uncensored:
                            continue
                        if is_hd is not None and video.get('is_hd', False) != is_hd:
                            continue
                        if is_zh is not None and video.get('is_zh', False) != is_zh:
                            continue
                        
                        # æ¼”å‘˜å’Œæ ‡ç­¾æ£€æŸ¥ï¼ˆåŒä¸Šï¼‰
                        if required_actor_id:
                            actors = video.get('actors', [])
                            actor_ids = [a.get('id') for a in actors]
                            if required_actor_id not in actor_ids:
                                continue
                        
                        if exclude_actor_id:
                            actors = video.get('actors', [])
                            actor_ids = [a.get('id') for a in actors]
                            if exclude_actor_id in actor_ids:
                                continue
                        
                        if required_tags:
                            tags = video.get('tags', [])
                            tag_names = [t.get('name').lower() for t in tags]
                            if not all(tag.lower() in tag_names for tag in required_tags):
                                continue
                        
                        if exclude_tags:
                            tags = video.get('tags', [])
                            tag_names = [t.get('name').lower() for t in tags]
                            if any(tag.lower() in tag_names for tag in exclude_tags):
                                continue
                    else:
                        video['detail_missing'] = True
                
                final_filtered.append(video)
                
                # é™åˆ¶è¡¥å……æ•°é‡
                if len(final_filtered) >= 50:
                    break
        
        logger.info(f"æœ€ç»ˆç­›é€‰å¾—åˆ° {len(final_filtered)} ä¸ªç¬¦åˆæ¡ä»¶çš„è§†é¢‘")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, final_filtered)
        return final_filtered
    
    def _get_video_detail(self, num: str) -> Optional[Dict[str, Any]]:
        """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"detail_{num}"
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡º
            pass
            return cached_data
            
        try:
            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…é¢‘ç¹è¯·æ±‚
            delay = randint(5, 10)
            # å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œåªè®°å½•å…³é”®ä¿¡æ¯
            if delay > 8:  # åªåœ¨å»¶è¿Ÿè¾ƒé•¿æ—¶è®°å½•
                logger.info(f"è·å–è§†é¢‘ {num} è¯¦æƒ…å‰ç­‰å¾… {delay} ç§’...")
            time.sleep(delay)
            
            # ä½¿ç”¨ç°æœ‰çš„spider.get_videoæ–¹æ³•
            video_detail = spider.get_video(num)
            if video_detail:
                detail_data = {
                    'is_hd': getattr(video_detail, 'is_hd', False),
                    'is_zh': getattr(video_detail, 'is_zh', False),  
                    'is_uncensored': getattr(video_detail, 'is_uncensored', False),
                    'actors': getattr(video_detail, 'actors', []),
                    'tags': getattr(video_detail, 'tags', []),
                    'downloads': getattr(video_detail, 'downloads', []),
                }
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_cache(cache_key, detail_data)
                return detail_data
            return None
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯¦æƒ…å‡ºé”™: {str(e)}, è§†é¢‘: {num}")
            logger.debug(traceback.format_exc())
            return None
            
    def _save_to_cache(self, key: str, data: Any) -> None:
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        self._cache[key] = {
            'data': data,
            'timestamp': datetime.now()
        }
        # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡º
        pass
        
    def _get_from_cache(self, key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®ï¼Œå¦‚æœæœ‰æ•ˆè¿”å›æ•°æ®ï¼Œå¦åˆ™è¿”å›None"""
        if key not in self._cache:
            return None
            
        cache_entry = self._cache[key]
        cache_time = cache_entry['timestamp']
        now = datetime.now()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if now - cache_time > timedelta(hours=self.cache_ttl_hours):
            # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡º
            pass
            return None
            
        return cache_entry['data']


# å…¨å±€å®ä¾‹
video_collector = VideoCollector()